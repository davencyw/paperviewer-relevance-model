{
    "reward_num_epochs": 10,
    "reward_per_device_train_batch_size": 2,
    "reward_save_steps": 10,
    "reward_save_total_limit": 2,
    "reward_logging_steps": 10,
    "reward_learning_rate": 1e-4,
    "reward_weight_decay": 0.01,
    "ppo_num_epochs": 10,
    "ppo_per_device_train_batch_size": 2,
    "ppo_save_steps": 10,
    "ppo_save_total_limit": 2,
    "ppo_logging_steps": 10,
    "ppo_learning_rate": 5e-5,
    "ppo_weight_decay": 0.01,
    "value_model_num_epochs": 10,
    "value_model_per_device_train_batch_size": 2,
    "value_model_save_steps": 10,
    "value_model_save_total_limit": 2,
    "value_model_logging_steps": 10,
    "value_model_learning_rate": 1e-5,
    "value_model_weight_decay": 0.02,
    "sampling_top_k": 50,
    "sampling_temperature": 1.0,
    "sampling_top_p": 0.9
}